{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.7.0 ('venv': venv)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'd:/projects/vsCode/pythonForHtests/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.10.2+cu113 torchvision==0.11.3+cu113 torchaudio===0.10.2+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
    "!pip3 install -q \"monai-weekly[nibabel, skimage, pillow, tensorboard, gdown, ignite, torchvision, itk, tqdm, lmdb, psutil,  openslide, pandas, einops, transformers, mlflow, matplotlib, tensorboardX, tifffile, imagecodecs]\"\n",
    "!pip3 install h5py\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "!pip install -q pytorch-lightning\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'monai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2316\\510085982.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_determinism\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m from monai.transforms import (\n\u001b[0;32m      5\u001b[0m     \u001b[0mAsDiscrete\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'monai'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "\n",
    ")\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from monai.transforms import (\n",
    "    LoadImage, LoadImaged, EnsureChannelFirstd,\n",
    "    Resized,  Compose\n",
    ")\n",
    "from monai.config import print_config\n",
    "import re\n",
    "import pytorch_lightning\n",
    "from monai.utils import set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, list_data_collate, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from monai.config import print_config\n",
    "#print_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "set_determinism(seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import *\n",
    "\n",
    "set_determinism(seed=0)\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
    "            1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(pytorch_lightning.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._model = UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "            norm=Norm.BATCH,\n",
    "        )\n",
    "        self.loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "        self.post_pred = Compose([EnsureType(\"tensor\", device=\"cpu\"), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "        self.post_label = Compose([EnsureType(\"tensor\", device=\"cpu\"), AsDiscrete(to_onehot=2)])\n",
    "        self.dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "        self.best_val_dice = 0\n",
    "        self.best_val_epoch = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # set up the correct data path\n",
    "        data_dir = \"D:\\\\dataSets\\\\CTORGmini\\\\\"\n",
    "\n",
    "        train_images = sorted(glob.glob(os.path.join(data_dir, \"volumes 0-49\", \"*.nii.gz\")))\n",
    "\n",
    "        train_labels = sorted( glob.glob(os.path.join(data_dir, \"labels\", \"*.nii.gz\")))\n",
    "\n",
    "        data_dicts = [\n",
    "            {\"image\": image_name, \"label\": label_name}\n",
    "            for image_name, label_name in zip(train_images, train_labels)\n",
    "        ]\n",
    "        train_files, val_files = data_dicts[:-9], data_dicts[-9:]\n",
    "\n",
    "        # set deterministic training for reproducibility\n",
    "        set_determinism(seed=0)\n",
    "\n",
    "        # define the data transforms\n",
    "        train_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                AddChanneld(keys=[\"image\", \"label\"]),\n",
    "                Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                Spacingd(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    pixdim=(1.5, 1.5, 2.0),\n",
    "                    mode=(\"bilinear\", \"nearest\"),\n",
    "                ),\n",
    "                ScaleIntensityRanged(\n",
    "                    keys=[\"image\"], a_min=-57, a_max=164,\n",
    "                    b_min=0.0, b_max=1.0, clip=True,\n",
    "                ),\n",
    "                CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                # randomly crop out patch samples from\n",
    "                # big image based on pos / neg ratio\n",
    "                # the image centers of negative samples\n",
    "                # must be in valid image area\n",
    "                RandCropByPosNegLabeld(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    label_key=\"label\",\n",
    "                    spatial_size=(96, 96, 96),\n",
    "                    pos=1,\n",
    "                    neg=1,\n",
    "                    num_samples=4,\n",
    "                    image_key=\"image\",\n",
    "                    image_threshold=0,\n",
    "                ),\n",
    "                # user can also add other random transforms\n",
    "                #                 RandAffined(\n",
    "                #                     keys=['image', 'label'],\n",
    "                #                     mode=('bilinear', 'nearest'),\n",
    "                #                     prob=1.0,\n",
    "                #                     spatial_size=(96, 96, 96),\n",
    "                #                     rotate_range=(0, 0, np.pi/15),\n",
    "                #                     scale_range=(0.1, 0.1, 0.1)),\n",
    "                EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "            ]\n",
    "        )\n",
    "        val_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                AddChanneld(keys=[\"image\", \"label\"]),\n",
    "                Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                Spacingd(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    pixdim=(1.5, 1.5, 2.0),\n",
    "                    mode=(\"bilinear\", \"nearest\"),\n",
    "                ),\n",
    "                ScaleIntensityRanged(\n",
    "                    keys=[\"image\"], a_min=-57, a_max=164,\n",
    "                    b_min=0.0, b_max=1.0, clip=True,\n",
    "                ),\n",
    "                CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # we use cached datasets - these are 10x faster than regular datasets\n",
    "        self.train_ds = CacheDataset(\n",
    "            data=train_files, transform=train_transforms,\n",
    "            cache_rate=1.0, num_workers=4,\n",
    "        )\n",
    "        self.val_ds = CacheDataset(\n",
    "            data=val_files, transform=val_transforms,\n",
    "            cache_rate=1.0, num_workers=4,\n",
    "        )\n",
    "#         self.train_ds = monai.data.Dataset(\n",
    "#             data=train_files, transform=train_transforms)\n",
    "#         self.val_ds = monai.data.Dataset(\n",
    "#             data=val_files, transform=val_transforms)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            self.train_ds, batch_size=2, shuffle=True,\n",
    "            num_workers=4, collate_fn=list_data_collate,\n",
    "        )\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            self.val_ds, batch_size=1, num_workers=4)\n",
    "        return val_loader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self._model.parameters(), 1e-4)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        output = self.forward(images)\n",
    "        loss = self.loss_function(output, labels)\n",
    "        tensorboard_logs = {\"train_loss\": loss.item()}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 4\n",
    "        outputs = sliding_window_inference(\n",
    "            images, roi_size, sw_batch_size, self.forward)\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        outputs = [self.post_pred(i) for i in decollate_batch(outputs)]\n",
    "        labels = [self.post_label(i) for i in decollate_batch(labels)]\n",
    "        self.dice_metric(y_pred=outputs, y=labels)\n",
    "        return {\"val_loss\": loss, \"val_number\": len(outputs)}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        val_loss, num_items = 0, 0\n",
    "        for output in outputs:\n",
    "            val_loss += output[\"val_loss\"].sum().item()\n",
    "            num_items += output[\"val_number\"]\n",
    "        mean_val_dice = self.dice_metric.aggregate().item()\n",
    "        self.dice_metric.reset()\n",
    "        mean_val_loss = torch.tensor(val_loss / num_items)\n",
    "        tensorboard_logs = {\n",
    "            \"val_dice\": mean_val_dice,\n",
    "            \"val_loss\": mean_val_loss,\n",
    "        }\n",
    "        if mean_val_dice > self.best_val_dice:\n",
    "            self.best_val_dice = mean_val_dice\n",
    "            self.best_val_epoch = self.current_epoch\n",
    "        print(\n",
    "            f\"current epoch: {self.current_epoch} \"\n",
    "            f\"current mean dice: {mean_val_dice:.4f}\"\n",
    "            f\"\\nbest mean dice: {self.best_val_dice:.4f} \"\n",
    "            f\"at epoch: {self.best_val_epoch}\"\n",
    "        )\n",
    "        return {\"log\": tensorboard_logs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': 'D:\\\\dataSets\\\\CTORGmini\\\\volumes 0-49\\\\volume-0.nii.gz',\n",
       "  'label': 'D:\\\\dataSets\\\\CTORGmini\\\\labels\\\\labels-0.nii.gz'},\n",
       " {'image': 'D:\\\\dataSets\\\\CTORGmini\\\\volumes 0-49\\\\volume-1.nii.gz',\n",
       "  'label': 'D:\\\\dataSets\\\\CTORGmini\\\\labels\\\\labels-1.nii.gz'},\n",
       " {'image': 'D:\\\\dataSets\\\\CTORGmini\\\\volumes 0-49\\\\volume-2.nii.gz',\n",
       "  'label': 'D:\\\\dataSets\\\\CTORGmini\\\\labels\\\\labels-2.nii.gz'},\n",
       " {'image': 'D:\\\\dataSets\\\\CTORGmini\\\\volumes 0-49\\\\volume-3.nii.gz',\n",
       "  'label': 'D:\\\\dataSets\\\\CTORGmini\\\\labels\\\\labels-3.nii.gz'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"D:\\\\dataSets\\\\CTORGmini\\\\\"\n",
    "\n",
    "train_images = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"volumes 0-49\", \"*.nii.gz\")))\n",
    "\n",
    "train_labels = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"labels\", \"*.nii.gz\")))\n",
    "\n",
    "data_dicts = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(train_images, train_labels)\n",
    "]\n",
    "data_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumberFromFilePath(dat):\n",
    "    string = str(dat['image_meta_dict']['filename_or_obj'])\n",
    "    numb = re.search('.nii', string).span()[0] ## this does what you wanted\n",
    "    describingNumber = string[(numb-2):(numb)].replace(\"-\",\"\")\n",
    "    return int(describingNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Project-MONAI/MONAI/discussions/3906\n",
    "# below example how to filter out the files without spacing and orientation in metadata \n",
    "# >>> from monai.transforms import LoadImaged\n",
    "# >>> data_dict = LoadImaged(keys=\"img\")({\"img\": \"./volume-20.nii.gz\"})\n",
    "# >>> (data_dict[\"img_meta_dict\"][\"qform_code\"], data_dict[\"img_meta_dict\"][\"sform_code\"])\n",
    "# (array(0, dtype=int16), array(0, dtype=int16))\n",
    "\n",
    "# >>> data_dict = LoadImaged(keys=\"img\")({\"img\": \"./volume-21.nii.gz\"})\n",
    "# >>> (data_dict[\"img_meta_dict\"][\"qform_code\"], data_dict[\"img_meta_dict\"][\"sform_code\"])\n",
    "# (array(1, dtype=int16), array(1, dtype=int16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=data_dicts, transform=val_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "\n",
    "for dat in check_loader:\n",
    "    # describingNumber = getNumberFromFilePath(dat)\n",
    "    # grp = f.create_group(str(describingNumber))\n",
    "\n",
    "    # labelBoolTensor =torch.where( dat['label']==1, 1, 0).bool()\n",
    "    # summ= torch.sum(labelBoolTensor)\n",
    "    # #if summ>0:\n",
    "    # labelBoolDataset = grp.create_dataset('liver', data=  (labelBoolTensor[0,0,:,:,:]).detach().numpy())\n",
    "    # imageDataset = grp.create_dataset('image', data=  (dat['image'][0,0,:,:,:]).detach().numpy())\n",
    "    # labelBoolDataset.attrs['sum']=  summ\n",
    "    \n",
    "    # print( labelBoolTensor[0,0,:,:,:].size() )\n",
    "\n",
    "    # imageDataset.attrs['dataType']=  \"CT\"\n",
    "    # labelBoolDataset.attrs['dataType']=  \"boolLabel\"\n",
    "\n",
    "    # #seting spacing - needs to be the same for all of the arrays in a grop - so the same for all images in patient\n",
    "    # grp.attrs['spacing']=(1,1,1)\n",
    "\n",
    "    # #get minimum and maximum values\n",
    "    # imageDataset.attrs['min']=torch.min(dat['image'])\n",
    "    # imageDataset.attrs['max']=torch.max(dat['image'])\n",
    "\n",
    "    # labelBoolDataset.attrs['min']=0\n",
    "    # labelBoolDataset.attrs['max']=1\n",
    "\n",
    "  \n",
    "\n",
    "    # print(describingNumber)\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8f1dbbf69973cc4b6583c327e15469e0625ce5e766b6de5a5209808bda28079"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
